{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18624a7f",
   "metadata": {},
   "source": [
    "### Ensembled_Technique & Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ccd1b",
   "metadata": {},
   "source": [
    "There are 3 Ensembled Technique \n",
    "\n",
    "1.Bagging\n",
    "\n",
    "2.Boosting\n",
    "\n",
    "3.Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576b705",
   "metadata": {},
   "source": [
    "#### Bagging ~ Bootstrap Aggregation\n",
    "It Create Random Sample of Datapoint(Random Train Set) with Sampling with Replacement(A Particular Datapoints can be repeated in multiple Random sample)\n",
    "\n",
    "Independent of Previous Model (Parallel in nature)\n",
    "\n",
    "prediction Average / mode is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8a8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "\n",
    "#Importing the Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Load the data set\n",
    "claimants = pd.read_csv(\"C:/Users/Akaash/Downloads/claimants.csv\")\n",
    "\n",
    "#Dropping the case number columns as it is not required\n",
    "claimants.drop([\"CASENUM\"],inplace=True,axis = 1)\n",
    "\n",
    "# Removing NA values in data set\n",
    "claimants = claimants.dropna()\n",
    "\n",
    "# Dividing our data into input and output variables \n",
    "X = claimants.iloc[:,1:]\n",
    "Y = claimants.iloc[:,0]\n",
    "\n",
    "# Creating K-Fold Instance\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=10,random_state=seed,shuffle = True)\n",
    "\n",
    "#Creating the Instance of DecisionTreeClassifier()\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "#Training the Model -- Bagging\n",
    "num_trees = 60\n",
    "#base_estimator= instance of the Technique used which is either DTclassifier or DTRegressor\n",
    "model = BaggingClassifier(base_estimator=classifier,n_estimators=num_trees,random_state=seed) \n",
    "\n",
    "#Predicting & Getting the Model Score with kfold\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579801bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7       , 0.68181818, 0.64545455, 0.64545455, 0.73636364,\n",
       "       0.70909091, 0.65137615, 0.71559633, 0.65137615, 0.62385321])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy for Each K-Fold\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe85db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.60383653044204"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average of All k-fold Accuracy to get Final model Accuary\n",
    "results.mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b226d95",
   "metadata": {},
   "source": [
    "Inference: Using the Bagging Ensembled Technique the Final Accuracy is 67.60% which is around 4% less from which i got with out Bagging Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7212a",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "It is Based on the Concept og Bagging where Datapoint are Randomly Sampled.\n",
    "\n",
    "It Splits Data Point as well as the features Randomly and Creates Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5027c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "#Importing the Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Load the data set\n",
    "claimants = pd.read_csv(\"C:/Users/Akaash/Downloads/claimants.csv\")\n",
    "\n",
    "#Dropping the case number columns as it is not required\n",
    "claimants.drop([\"CASENUM\"],inplace=True,axis = 1)\n",
    "\n",
    "# Removing NA values in data set\n",
    "claimants = claimants.dropna()\n",
    "\n",
    "# Dividing our data into input and output variables \n",
    "X = claimants.iloc[:,1:]\n",
    "Y = claimants.iloc[:,0]\n",
    "\n",
    "# Creating K-Fold Instance\n",
    "kfold = KFold(n_splits=10, random_state=7,shuffle = True)\n",
    "\n",
    "#Training the Model ~ Random Forest \n",
    "num_trees = 100\n",
    "max_features = 2\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features) #max_features will sample randomly 2 Features\n",
    "\n",
    "#Predicting & Getting the Model Score with kfold\n",
    "results = cross_val_score(model, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ed556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73636364, 0.7       , 0.60909091, 0.64545455, 0.70909091,\n",
       "       0.72727273, 0.69724771, 0.77981651, 0.64220183, 0.63302752])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy for Each K-Fold\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48df37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.79566305254379"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average of All k-fold Accuracy to get Final model Accuary\n",
    "results.mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920a6e6",
   "metadata": {},
   "source": [
    "Inference: Using The Random Forest the Final Accuracy is 69.43%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3ea65",
   "metadata": {},
   "source": [
    "#### Boosting ~ AdaBoost\n",
    "Stage Weight of That Datapoint Who give Error is updated in the next Training Set of Next model, and the Next Model Try to minimize the Error / Boost the Performance of the model\n",
    "\n",
    "It is Dependent on the Previous model i.e sequential in Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c18190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classification\n",
    "\n",
    "#Importing the Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Load the data set\n",
    "claimants = pd.read_csv(\"C:/Users/Akaash/Downloads/claimants.csv\")\n",
    "\n",
    "#Dropping the case number columns as it is not required\n",
    "claimants.drop([\"CASENUM\"],inplace=True,axis = 1)\n",
    "\n",
    "# Removing NA values in data set\n",
    "claimants = claimants.dropna()\n",
    "\n",
    "# Dividing our data into input and output variables \n",
    "X = claimants.iloc[:,1:]\n",
    "Y = claimants.iloc[:,0]\n",
    "\n",
    "# Creating K-Fold Instance\n",
    "seed=7\n",
    "kfold = KFold(n_splits=10, random_state=seed,shuffle = True)\n",
    "\n",
    "#Training the Model ~ Adaboost (Boosting)\n",
    "num_trees = 15\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "#Predicting & Getting the Model Score with kfold\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc04cda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81818182, 0.70909091, 0.68181818, 0.71818182, 0.77272727,\n",
       "       0.70909091, 0.74311927, 0.73394495, 0.71559633, 0.67889908])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy for Each K-Fold\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de4d992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.80650542118433"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average of All k-fold Accuracy to get Final model Accuary\n",
    "results.mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377275f",
   "metadata": {},
   "source": [
    "Inference: Using the Boosting Ensembled Technique the Final Accuracy is 72.80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2323ea",
   "metadata": {},
   "source": [
    "#### Stacking\n",
    "\n",
    "Through Stacking Can Use Multiple Algorithms At Once the TAle mean/Mode of the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ad41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Ensemble for Classification\n",
    "\n",
    "#Importing the Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Load the data set\n",
    "claimants = pd.read_csv(\"C:/Users/Akaash/Downloads/claimants.csv\")\n",
    "\n",
    "#Dropping the case number columns as it is not required\n",
    "claimants.drop([\"CASENUM\"],inplace=True,axis = 1)\n",
    "\n",
    "# Removing NA values in data set\n",
    "claimants = claimants.dropna()\n",
    "\n",
    "# Dividing our data into input and output variables \n",
    "X = claimants.iloc[:,1:]\n",
    "Y = claimants.iloc[:,0]\n",
    "\n",
    "# Creating K-Fold Instance\n",
    "seed=7\n",
    "kfold = KFold(n_splits=10, random_state=seed,shuffle = True)\n",
    "\n",
    "# create the sub models - 3 Different Models\n",
    "estimators = []\n",
    "model1 = LogisticRegression(max_iter=500)\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "\n",
    "#Predicting & Getting the Model Score with kfold\n",
    "results = cross_val_score(ensemble, X, Y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7263ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72727273, 0.70909091, 0.60909091, 0.72727273, 0.70909091,\n",
       "       0.7       , 0.67889908, 0.68807339, 0.71559633, 0.71559633])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy for Each K-Fold\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fdbc11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.79983319432861"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average of All k-fold Accuracy to get Final model Accuary\n",
    "results.mean()*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2595aa4",
   "metadata": {},
   "source": [
    "Inference: Using the Stacking Ensembled Technique the Final Accuracy is 69.61%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2a209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
